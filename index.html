<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Joint Workshop on Next-Generation Language Models for KKR, Reasoning and Ethics in LLMs and on Statistics and Knowledge Integration for Logic and Learning (LLMs 2026)</title>
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-2B6Y0BV9D5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-2B6Y0BV9D5');
  </script>
</head>

<body>
  <header>
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
      <div class="container">
        <a class="navbar-brand" href="#">LLMs 2026</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarNav">
          <ul class="navbar-nav">
            <li class="nav-item">
              <a class="nav-link" href="#call-for-contributions">Call for Contributions</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="#important-dates">Important Dates</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="#organisation-and-pc-members">Organisation and PC Members</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="#program">Program</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="#accepted-papers">Accepted Papers</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="#invited-talks">Invited Talks</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>
  </header>

  <section class="jumbotron jumbotron-fluid mb-0">
    <div class="container">
      <h1 class="display-5">Joint Workshop on Next-Generation Language Models for KKR, Reasoning and Ethics in LLMs and on Statistics and Knowledge Integration for Logic and Learning (LLMs 2026)</h1>
      <p class="lead">associated with <a href="https://www.floc26.org/">Federated Logic Conference 2026</a></p>
    </div>
  </section>

  <!-- Notification: Call for Papers -->
  <div class="container mt-3">
    <div class="alert alert-info alert-dismissible fade show" role="alert">
      <strong>Call for Papers Now Open!</strong>
      We are pleased to announce that this joint workshop brings together three communities: Next-Generation Language Models for Knowledge Representation and Reasoning (NeLaMKRR), Ethics in Large Language Models (ReLLM), and Statistics and Knowledge Integration for Logic and Learning (SKILL).
      <button type="button" class="close" data-dismiss="alert" aria-label="Close">
        <span aria-hidden="true">&times;</span>
      </button>
    </div>

    <h2 id="call-for-contributions">Call for Contributions</h2>
    <p>This joint workshop brings together researchers and practitioners working on the intersections of language models, knowledge representation, reasoning, ethics, and statistics. We encourage submissions that discuss novel techniques, approaches, and innovative ideas related to these topics. The workshop aims to create a platform for researchers from different disciplines and AI perspectives to explore approaches and techniques that reconcile reasoning between language models using transformers and logic-based representations, while also addressing ethical considerations and statistical foundations of knowledge integration.</p>
    
    <h3>Workshop Scope</h3>
    <p>This workshop is a merger of three previously separate workshops:</p>
    <ul>
      <li><strong>Next-Generation Language Models for Knowledge Representation and Reasoning (NeLaMKRR):</strong> Focuses on analyzing reasoning abilities of language models, injecting KR-style reasoning into language models, and formalizing the kind of reasoning language models carry out.</li>
      <li><strong>Reasoning and Ethics in Large Language Models (ReLLM):</strong> Addresses ethical considerations, limitations, and responsible deployment of language models in various domains.</li>
      <li><strong>Statistics and Knowledge Integration for Logic and Learning (SKILL):</strong> Explores the integration of statistical methods with knowledge representation and logical reasoning in learning systems.</li>
    </ul>

    <h3>Topics of Interest</h3>
    <p>Topics of interest include, but are not limited to, the following:</p>
    <ul>
      <li>Language models' reasoning abilities and knowledge representation analysis</li>
      <li>Argumentation, negotiation, and agent-based reasoning in language models</li>
      <li>Infusing KR-style reasoning into language models</li>
      <li>Knowledge injection and extraction mechanisms in language models</li>
      <li>Qualitative assessment of reasoning accuracy in language models</li>
      <li>Techniques for enhancing language model reasoning predictability</li>
      <li>Formalizing language models' reasoning types</li>
      <li>Reasoning applications in medicine, law, and science domains</li>
      <li>Ethics and limitations of reasoning in language models</li>
      <li>Language model reasoning categories: Deductive, Inductive, Abductive</li>
      <li>Formal vs. informal 'common sense' reasoning comparison</li>
      <li>Chain of thought prompting investigation</li>
      <li>Prompting and in-context learning examination</li>
      <li>Problem decomposition strategies exploration</li>
      <li>Rationale engineering studies</li>
      <li>Bootstrapping and self-improvement methods evaluation</li>
      <li>Language models integration with knowledge graphs</li>
      <li>Unstructured data conversion to knowledge graphs</li>
      <li>Domain-specific language models development</li>
      <li>Research on neurosymbolic knowledge representation models</li>
      <li>Ethical considerations in LLM deployment and use</li>
      <li>Bias detection and mitigation in language models</li>
      <li>Fairness and transparency in LLM-based systems</li>
      <li>Statistical foundations of knowledge integration</li>
      <li>Probabilistic reasoning and uncertainty quantification in LLMs</li>
      <li>Integration of symbolic and statistical approaches</li>
      <li>Evaluation metrics for reasoning and ethical considerations</li>
    </ul>

    <h3>Submission Details</h3>
    <p>Contributions may be regular papers (up to 9 pages) or short/position papers (up to 5 pages), including abstract, figures, and appendices (if any) but excluding references and acknowledgements. Submissions should follow the <a href="https://kr.org/KR2026/files/KR26_authors_kit.zip">KR 2026 formatting guidelines</a> and be submitted through the <a href="https://submissions.floc26.org/llms">submission page</a>. Each submission will be reviewed by at least two program committee members.</p>
  </section>

  <section class="container" id="important-dates">
    <h2>Important Dates</h2>
    <ul>
      <li style="color:#6c757d; opacity:0.5;">Paper Submission Deadline: TBD</li>
      <li style="color:#6c757d; opacity:0.5;">Paper Notification: TBD</li>
      <li style="color:#6c757d; opacity:0.5;">Camera Ready: TBD</li>
      <li style="color:#6c757d; opacity:0.5;">Workshop Registration Deadline: TBD</li>
      <li>Workshop Date: July 18-19, 2026</li>
    </ul>
  </section>

  <!-- Program section 
  <section class="container" id="program">
    <h2>Program</h2>
    <p class="text-muted mb-3">Program details coming soon. Single-track schedule. All times are local.</p>
    <p class="text-center text-secondary"><em>TBD</em></p>
  </section>-->

  <section class="container" id="workshop-description">
    <h2>Workshop Description</h2>
    <p>Reasoning is an essential component of human intelligence as it plays a fundamental role in our ability to think critically, support responsible decisions, and solve challenging problems. Traditionally, AI has addressed reasoning in the context of logic-based representations of knowledge. However, the recent leap forward in natural language processing, with the emergence of language models based on transformers, is hinting at the possibility that these models exhibit reasoning abilities, particularly as they grow in size and are trained on more data. Despite ongoing discussions about what reasoning is in language models, it is still not easy to pin down to what extent these models are actually capable of reasoning.</p>
    
    <p>The goal of this workshop is to create a platform for researchers from different disciplines and/or AI perspectives, to explore approaches and techniques with the aim to reconcile reasoning between language models using transformers and using logic-based representations. The specific objectives include analyzing the reasoning abilities of language models measured alongside KR methods, injecting KR-style reasoning abilities into language models (including by neuro-symbolic means), and formalizing the kind of reasoning language models carry out. This exploration aims to uncover how language models can effectively integrate and leverage knowledge and reasoning with it, thus improving their application and utility in areas where precision and reliability are a key requirement.</p>
    
    <p>Furthermore, as language models become increasingly prevalent in society, it is crucial to address the ethical implications of their deployment and use. This workshop brings together perspectives on ethical considerations in LLM development and deployment, including issues of bias, fairness, transparency, and accountability. Additionally, the workshop explores the statistical foundations underlying knowledge integration and the interplay between symbolic and statistical approaches in learning systems.</p>
    
    <p>By merging these three communities—NeLaMKRR, ReLLM, and SKILL—we aim to foster interdisciplinary collaboration and create a comprehensive forum for discussing the latest advances in language models, their reasoning capabilities, ethical implications, and the statistical and logical foundations that underpin effective knowledge integration in AI systems.</p>
  </section>

  <!--<section class="container" id="accepted-papers">
    <h2>Accepted Papers</h2>
    <p class="text-center text-secondary"><em>TBD</em></p>
  </section>-->

  <!-- Invited Talks section -->
  <!--<section class="container" id="invited-talks">
    <h2>Invited Talks</h2>
    <p class="text-center text-secondary"><em>TBD</em></p>
  </section>-->

  <section class="container" id="organisation-and-pc-members">
    <h2>Organisation and PC Members</h2>
    
    <h3>Organisers</h3>
    <ul>
      <li>Ha Thanh Nguyen, Research and Development Center for Large Language Models, National Institute of Informatics (NII), Tokyo, Japan</li>
      <li>Francesca Toni, Department of Computing, Imperial College London, United Kingdom</li>
      <li>Kostas Stathis, Department of Computer Science, Royal Holloway University of London, United Kingdom</li>
      <li>Ken Satoh, Center for Juris-Informatics, ROIS-DS, Tokyo, Japan</li>
      <li>Randy Goebel, Alberta Machine Intelligence Institute, University of Alberta, Canada</li>
      <li>Nourhan Ehab, German University in Cairo, Egypt</li>
      <li>Mervat Abuelkheir, German University in Cairo, Egypt</li>
      <li>Elena Umili, Department of Computer, Control and Management Engineering, Sapienza University of Rome, Italy</li>
      <li>Francesco Chiariello, RWTH Aachen University, Germany</li>
      <li>Yves Lesperance, Department of Electrical Engineering and Computer Science, York University, Canada</li>
      <li>Matteo Magnini, Department of Computer Science and Engineering, University of Bologna, Italy</li>
      <li>Federico Sabbatini, Department of Pure and Applied Sciences, University of Urbino Carlo Bo, Italy</li>
    </ul>

    <h3>Program Committee Members (Tentative)</h3>
    <ul>
      <li>Agnieszka Mensfelt, Royal Holloway, University of London, United Kingdom</li>
      <li>Daniel Sonntag, German Research Center for Artificial Intelligence (DFKI), Saarbrücken &amp; Oldenburg, Germany</li>
      <li>Gabriel Freedman, Imperial College London, United Kingdom</li>
      <li>John D. Martin, Openmind Research Institute, Edmonton, Alberta, Canada</li>
      <li>Lihu Chen, Imperial College London, United Kingdom</li>
      <li>María Navas-Loro, Universidad Politécnica de Madrid, Spain</li>
      <li>May Myo Zin, Center for Juris-Informatics, ROIS-DS, Tokyo, Japan</li>
      <li>Minh-Phuong Nguyen, Japan Advanced Institute of Science and Technology, Ishikawa, Japan</li>
      <li>Sabine Wehnert, Otto-von-Guericke University Magdeburg, Germany</li>
      <li>Thi-Hai-Yen Vuong, VNU University of Engineering and Technology, Vietnam National University, Hanoi, Vietnam</li>
      <li>Vince Trencsenyi, Royal Holloway University of London, United Kingdom</li>
      <li>Vu Tran, Japan Advanced Institute of Science and Technology, Ishikawa, Japan</li>
      <li>Wachara Funwacharakorn, Center for Juris-Informatics, ROIS-DS, Tokyo, Japan</li>
    </ul>
  </section>

    <footer class="bg-dark text-center py-3">
    <p class="text-white">&copy;2026 LLMs. All rights reserved.</p>
    <a class="text-white" href="https://llms-workshop.github.io/2026/">LLMs 2026 home page</a>
  </footer>

  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"></script>
  <!-- Bootstrap JS (v4.5.2) dependencies -->
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
</body>
</html>
